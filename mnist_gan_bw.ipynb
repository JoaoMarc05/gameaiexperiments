{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Test CNN network\n",
    "## Change random sampler to Gaussian distribution\n",
    "## Experiment with https://github.com/soumith/ganhacks hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers import Input,merge\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.regularizers import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import random, sys, keras\n",
    "from keras.models import Model, Sequential\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #On rd010532 0 = Tesla, 1 = Quadro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_model_on_interactive_session(model):\n",
    "\n",
    "    display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(np.min(X_train), np.max(X_train))\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Generative model ...\n",
    "opt = Adam(lr=1e-4)\n",
    "\n",
    "generator = Sequential(name='generator')\n",
    "generator.add(Dense(3136, input_shape=(100,), activation='relu'))\n",
    "generator.add(Reshape((56, 56, 1)))\n",
    "generator.add(Conv2D(50, (3, 3),activation='relu', padding='same'))\n",
    "generator.add(Conv2D(25, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "generator.add(Conv2D(1, (1, 1), activation='sigmoid', padding='same'))\n",
    "\n",
    "generator.compile(loss='mean_squared_error', optimizer=opt)\n",
    "generator.summary()\n",
    "draw_model_on_interactive_session(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialise_generator():\n",
    "    X_train[0:1000].shape\n",
    "    y = np.random.normal(0,1,size=[1000,100])\n",
    "\n",
    "    generator.fit(y, X_train[0:1000], epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build Discriminative model ...\n",
    "dopt = Adam(lr=1e-3)\n",
    "\n",
    "discriminator = Sequential(name='discriminator')\n",
    "discriminator.add(Dense(28 * 28 * 1, input_shape=(28, 28, 1)))\n",
    "discriminator.add(Conv2D(32, (5, 5), strides=(2, 2), padding='same', activation='relu'))\n",
    "discriminator.add(Conv2D(32, (5, 5), strides=(2, 2), padding='same', activation='relu'))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(256, activation='relu'))\n",
    "discriminator.add(Dense(1, activation='tanh'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=dopt)\n",
    "#discriminator.compile(loss=GAN_loss_function, optimizer=dopt)\n",
    "discriminator.summary()\n",
    "\n",
    "draw_model_on_interactive_session(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze weights in the network for when using stacked training\n",
    "def make_trainable(network, val):\n",
    "    network.trainable = val\n",
    "    \n",
    "    for layer in network.layers:\n",
    "        layer.trainable = val\n",
    "\n",
    "    network.compile(loss=network.loss, optimizer=network.optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build stacked GAN model\n",
    "# need new loss function here? Maximise entropy between two classes while\n",
    "#discriminator is trying to reduce it?\n",
    "\n",
    "GAN = Sequential()\n",
    "GAN.add(generator)\n",
    "GAN.add(discriminator)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "GAN.summary()\n",
    "\n",
    "draw_model_on_interactive_session(GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = {'d':[], 'g':[], 'accuracy':[]}\n",
    "\n",
    "\n",
    "def plot_loss(losses):   \n",
    "    \n",
    "    if ax.lines:\n",
    "        ax.lines[0].set_data(list(range(len(losses[\"d\"]))), losses[\"d\"])\n",
    "        ax.lines[1].set_data(list(range(len(losses[\"g\"]))), losses[\"g\"])\n",
    "        ax.lines[2].set_data(list(range(len(losses[\"accuracy\"]))), losses[\"accuracy\"])\n",
    "        ax.autoscale(True)\n",
    "        \n",
    "    else:        \n",
    "        ax.plot(list(range(len(losses[\"d\"]))), losses[\"d\"], label='discriminator loss')\n",
    "        ax.plot(list(range(len(losses[\"g\"]))), losses[\"g\"], label='generator loss')\n",
    "        ax.plot(list(range(len(losses[\"accuracy\"]))), losses[\"accuracy\"], label='accuracy')\n",
    "        ax.autoscale()        \n",
    "        \n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    ax.legend(['Discriminator Loss', 'Generator Loss', 'Discriminator Accuracy'])\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    \n",
    "def plot_gen(n_ex=16,dim=(4,4), figsize=(10,10) ):\n",
    "    \n",
    "    noise = np.random.normal(0,1,size=[n_ex,100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    for i in range(generated_images.shape[0]):\n",
    "        #plt.subplot(dim[0],dim[1],i+1)\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_images[i,:,:,0]\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    image_fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrain_discriminator():\n",
    "    make_trainable(discriminator,True)\n",
    "\n",
    "    X, y = generate_discriminator_training_batch(30000)\n",
    "    \n",
    "    discriminator.fit(X, y, epochs=1, batch_size=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = 100\n",
    "\n",
    "def perform_discriminator_training_steps(n_steps=1):\n",
    "    make_trainable(discriminator,True)\n",
    "\n",
    "    X, y = generate_discriminator_training_batch(ntrain)\n",
    "\n",
    "    discriminator_history = 0\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        discriminator_history = discriminator.train_on_batch(X,y)\n",
    "\n",
    "    losses['d'].append(discriminator_history)\n",
    "\n",
    "    y_hat = discriminator.predict(X)\n",
    "\n",
    "    accuracy, n_right, n_total = calculate_discriminator_accuracy(X, y)\n",
    "\n",
    "    losses['accuracy'].append(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_discriminator_training_batch(batch_size):\n",
    "    trainidx = random.sample(range(0,X_train.shape[0]), int(batch_size/2))\n",
    "    XT = X_train[trainidx,:,:,:]\n",
    "\n",
    "    noise_gen = np.random.normal(0,1,size=[int(batch_size/2),100])\n",
    "\n",
    "    generated_images = generator.predict(noise_gen)\n",
    "    X = np.concatenate((XT, generated_images))\n",
    "    n = XT.shape[0]\n",
    "    y = np.zeros([2*n])\n",
    "    y[:n] = 1 #real sample = 1\n",
    "    y[n:] = 0 #generated sample = 0\n",
    "\n",
    "    #X, y = shuffle(X, y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_discriminator_accuracy(input_images, labels):\n",
    "    \n",
    "    def measure_accuracy(labels, predicted):\n",
    "        # Measure accuracy of pre-trained discriminator network\n",
    "        predicted = np.around(predicted)\n",
    "        total_correct = sum(predicted == labels)[0]\n",
    "        accuracy = total_correct*100.0/len(labels)\n",
    "        return accuracy, total_correct, len(labels)\n",
    "\n",
    "    \n",
    "    y_predicted = discriminator.predict(input_images)\n",
    "\n",
    "    accuracy, n_right, n_total = measure_accuracy(labels, y_predicted)\n",
    "    return accuracy, n_right, n_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "def perform_generator_training_steps(n_steps=1):\n",
    "    noise_tr = np.random.normal(0,1,size=[ntrain, 100])\n",
    "    y2 = np.zeros([ntrain])\n",
    "    y2[:] = 1 #pretend that the generated images are real\n",
    "\n",
    "    make_trainable(discriminator, False)\n",
    "\n",
    "    #GAN.layers[2].layers[6].trainable\n",
    "    #gan_history = GAN.fit(noise_tr, y2, epochs=10, shuffle=True )\n",
    "    gan_history = 0\n",
    "    for _ in range(n_steps):\n",
    "        gan_history = GAN.train_on_batch(noise_tr, y2)\n",
    "        \n",
    "    losses['g'].append(gan_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perform_generator_training_steps(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_discriminator_training_steps(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "image_fig, image_ax = plt.subplots(1, 1)\n",
    "\n",
    "for _ in range(6000):\n",
    "    perform_discriminator_training_steps(1)\n",
    "    perform_generator_training_steps(1)\n",
    "\n",
    "    fig\n",
    "    plot_loss(losses)\n",
    "        \n",
    "    image_fig\n",
    "    plot_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.predict(np.random.normal(0,1,size=[1,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.predict(np.array([X_train[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
